\documentclass[../main/main.tex]{subfiles}

\newdate{date}{29}{10}{2020}


\begin{document}

We recall now one of the most important result of the last lecture: if the network is large enough, for \( N \rightarrow \infty  \), the \textbf{epidemic threshold} tends to zero:
\begin{equation}
    \beta_c \xrightarrow{N \to \infty} 0
\end{equation}
Moreover, the epidemic threshold for IBMF depends on the largest eigenvalue of the adjacency matrix $\Lambda_{max}$.
The last relations which contain \( \beta _c \) for IBMF and DBMF, can tell us more about the accuracy of the model: \textbf{DBMF} is accurate only in the proximity of the epidemic threshold, while \textbf{IBMF} is accurate for the entire epidemic diagram. See the figure \ref{fig:09_3}.
\marginpar{ \textbf{Lecture 9.} \\  \displaydate{date}. \\ Compiled:  \today.}

\begin{figure}[h!]
\centering
\includegraphics[width=0.7\textwidth]{../lessons/image/09/3.png}
\caption{\label{fig:09_3} The quenched mean field (IBMF) curve follows exactly the simulation, while DBMF the is precise only around the epidemic threshold.}
\end{figure}

We want now to discuss what are the reasons behind this important result. Since we know there is a strong connection between these two theories, it would be of our interest to derive DBMF from IBMF. Once again, we shall repeat that in \textbf{annealed networks} we are not considering a single network but an \textbf{average} of all the \textit{possible random networks} that can be generated \textit{from a degree distribution}. Instead, in the \textbf{quenched networks} we pick a particular \textbf{one}, and we compute the result for \textit{that specific network}. Then, nothing prevents us to run our model on that network and iterate multiple times.

Let us try to characterize the \textbf{annealed network}, in particular we want to see the \textit{adjacency matrix} looks like.
We start from:
\begin{equation*}
  \dot{\rho }_i = - \mu \rho _i + (1 - \rho _i) q_i \qquad \text{ where } \quad q_i = 1- \prod_{j=1}^{N} \qty[ 1 - \beta A_{ij} \rho _j]
\end{equation*}
In this case, the \textbf{adjacency matrix} is replaced by an \textbf{Annealed Adjacency Matrix} (\textbf{AAM}) whose general form is:
\begin{equation}
  \bar{A}_{ij} = \frac{k_j P(k_i|k_j)}{N P (k_i)}
\end{equation}
which for \emph{random networks} becomes:
\begin{equation*}
  \bar{A}_{ij} = \frac{k_i k_j}{N \expval{k} } = \frac{k_i k_j}{2 L}
\end{equation*}
where the probability  \(  P(k_i|k_j) \) of picking a random node becomes \( k_j \). This is the number of trials we have available in order to create this specific connection  \( i,j \), over all the possible connections that the network can return.
If we substitute the explicit form of the adjiacency matrix in the expression of \( q_i \):
\begin{equation*}
  q_i = 1 - \prod_{j=1}^{N} \qty[1 - \beta \frac{k' P(k'|k)}{N_{k'}} \rho _j]
\end{equation*}


And starting from individual nodes and heading towards more general degree classes:
\begin{equation*}
  \dot{\rho }_k = - \mu \rho _k + (1- \rho _k)\left[ 1 - \prod_{k'} \qty[1 - \beta \frac{k P(k'|k)}{N_{k'}} \rho _k]^{N_{k'}} \right]
\end{equation*}
this is the most general expression that we can obtain for DBMF.
The multiplication can be replaced by a sum, only if assuming that \( \beta \rho _k \ll 1 \):
\begin{equation*}
  \dot{\rho }_ k = - \mu \rho_k + \beta k (1-\rho_k) \sum_{k'}P(k'|k)\rho_k'
\end{equation*}
And recalling that the expression for $\Theta_k = \sum_{k'}P(k'|k)\rho_{k'}$:
\begin{equation*}
   \dot{\rho }_ k = - \mu \rho_k + \beta k (1-\rho_k) \Theta_k
\end{equation*}
which is the formula obtained for DBMF. Hence, in the DBMF we are implicitly assuming that  \( \beta \rho _k \ll 1 \). This is the reason why DBMF is accurate only around the epidemic threshold. At the end, we are able to pass from IBMF to DBMF and actually we are explaining the difference in the accuracy between the two models.








\subsection{IBMF and Pair approximation}

Let us make a very brief overview about what means to \textbf{cut down} the chain to \textbf{pair approximation}.
Up to now, all the models we have seen were cut at the \textit{individual level} which means that \( \text{Prob} [\sigma _i (t)=0] \) and \( \text{Prob} [\sigma _j (t) = 0] \) are statistically independent. Now, instead, let us consider the joint probability of being infected, given that we we susceptible and given that a neighbor of ours was infected:
\begin{equation*}
  \dv{}{t} \rho (i,t) = - \mu \rho (i,t) + \beta \sum_{j}^{} A_{ij} \text{Prob} [\sigma _i(t)=0, \sigma _j(t)=1]
\end{equation*}
we look for an approximation for this joint probability, and this time we choose to cut the chain at the level of a single link $(i,j)$.
We want to see actually how $P\{\sigma_i(t) = 0\ ,\   \sigma_j (t) = 1\}$ changes in the equation for $\dot{\rho}$ (this involves three nodes terms and so on).
Hence we obtain:
\begin{equation*}
  \dv{}{t} \rho (i,t) = - \mu \rho (i,t) + \beta \sum_{j}^{} A_{ij} \rho (j,t) - \beta \sum_{j}^{} A_{ij} \mathbb{E} \qty[X_i (t) X_j (t)]
\end{equation*}
where \(  \mathbb{E} \qty[X_i (t) X_j (t)] \) is the two nodes expectation probability of being infected.

However, we need to look for an expression for the $\binom{N}{2}$ equations for \(  \mathbb{E}  \qty[X_i (t) X_j (t)] \), since we have to take into account one expression for each node multiplied all possible link we can have in the network.
The main idea is:
\begin{equation}
\begin{split}
  \dv{}{t} E \qty[X_i (t) X_j (t)] &=  - 2 \mu \mathbb{E} \qty[X_i (t) X_j (t)] + \beta \sum_{k}^{} A_{ik} \mathbb{E} \qty[X_j (t) X_k (t)]  \\
  & + \beta \sum_{k}^{} A_{jk} \mathbb{E} \qty[X_i (t) X_k (t)]  - \beta
  \sum_{k}^{} (A_{ik}+A_{jk}) \mathbb{E} \qty[X_i (t) X_j (t) X_k (t)]
\end{split}
\end{equation}

Let us analyze the terms on the rhs. The first one is the \textbf{recovery term} and needs both of \textit{them to be infected}. On the other hand the second and third terms are the \textbf{infection terms}, where either one of the node is already infected and the susceptible term gets infected from any other neighbour. The last term has to be put in order to discard the three nodes expectations, and here comes the need for an \textbf{approximation}, namely a \textbf{closure}.

The most used closures used in the literature are:
\begin{equation*}
   \mathbb{E} \qty[X_i (t) X_j (t) X_k (t)]   =  \mathbb{E} \qty[X_i (t) X_j (t)]  \mathbb{E}[X_k (t)]
\end{equation*}
where in this case the third term we factorize out is the \textit{mean-field} term. Alternatively:
\begin{equation*}
  \mathbb{E} \qty[X_i (t) X_j (t) X_k (t)]   = \frac{\mathbb{E} \qty[X_i (t) X_j (t)] \mathbb{E}[X_j (t) X_k (t)]  }{\mathbb{E}[X_j (t)]}
\end{equation*}
where the second is similar to the first but we are considering the two extremes and then the probability that \( j \), the node in between, is infected.














\chapter{Epidemic Spreading on Networks: Advanced Models}

In this chapter, we are gonna study non-Markovian epidemic spreading. In the literature, it is not seen, but if you want to implement a realistic model it is very important.

\section{Markovian Models}

Despite it is difficult to find it discussed in literature, we surely need to take into account that \textbf{both} the \textbf{infection process} and \textbf{recovery process} in reality \textbf{DO NOT} have a constant rate.

All the models we have seen till now assume that \( \beta  \) (infection process) and \( \mu  \) (recovery process) are constant rates.
This means that movement between compartments takes place at constant rate, or equivalent the probability of jumping from one compartment to another does not depend on the time spent in the compartment. Essentially, we are considering a \textbf{memoryless process}.
The jump are memoryless, i.e. we are running a Markov chain.

The fundamental property of a Markov chain is called \textbf{Markov property}: \emph{the jump probability at time \( t + \Delta t \) does not depend on elapsed time, but only on \( t \)}, i.e. we have not to take into account the time that we spent in that compartment.
This property is very useful for mathematical treatments.

Jumps made at a constant rate (\( \beta  \) and \( \mu  \)) imply that the time spent inside each compartment \( \tau  \) follows a \textbf{exponential distribution} (Fig. \ref{fig:09_4}):
\begin{equation}
  P(x) = \tau e^{- \tau x}
\end{equation}
with mean \( \tau = \frac{1}{\mu }\), i.e. \( \tau  \) is the infectious period (average time spent in \( I \)).

\begin{figure}[h!]
\centering
\includegraphics[width=0.4\textwidth]{../lessons/image/09/4.png}
\caption{\label{fig:09_4} Exponential probability density function for different $\lambda = \tau$. Note as the most probable value is when we start our observation, namely at the moment in which $x=0$. }
\end{figure}


What are the implication of this property? The most important one is that an exponentially distributed infectious period implies that the most probable duration of the disease is 0. Indeed, the probability decreases with time.
More particularly, it depends on the mean, but in any case the most probable jump (time in which I am making the jump) is at the beginning.
It is something that is \textbf{not realistic}, indeed if you got influenza at least you will spend some time infected.
And actually, if you are looking how infectius period are distributed in real life, it is something which is quite different. For a disease, you know exactly when it starts but do not you know when it ends.
For instance, let us consider the left plot in Fig. \ref{fig:09_1} for 2009 H1N1 Influenza. For this type of diesease the plot show the distribtuion of the infectious period, which has as probable value 2 days and an half. The most important things is that it is not 0. On the right, we have also the estimates for Covid-19. One process we use to measure the infectious period is the \textbf{serial interval}, i.e. from symptoms to symptom. Or we have also the \textbf{generation time}, i.e. from infection to infection. Obviously, these are approximations but can give you some means.

\begin{figure}[h!]
\begin{minipage}[c]{0.5\linewidth}
\centering
\includegraphics[width=1\textwidth]{../lessons/image/09/1.png}
\end{minipage}
\begin{minipage}[]{0.5\linewidth}
\centering
\includegraphics[width=1\textwidth]{../lessons/image/09/2.png}
\end{minipage}
\caption{\label{fig:09_1} \textbf{Left:} Histogram of 1009 H1N1 Influenza. \textbf{Right:} distribution  of Covid-19. }
\end{figure}

The problem is that, all these results demonstrate that these kind of diseases are \emph{non-markovian}: \textbf{transition probability depends on the time spent in a compartment}. Indeed, patients usually spend some time infected before starting to recover.




\section{Non-Markovian Epidemic Spreading}

How are we gonna model this non markovianity?
What are the distribution that better describe what we saw in the data?

Patients usually spend some time infected before starting to recover. This situation is better approximated by a \textbf{Gamma distribution}:
\begin{equation}
  P(x) = \frac{1}{\Gamma (k) \theta ^k} x^{k-1} e^{- \frac{x}{\theta }}
\end{equation}
where \( k \) is the \emph{shape}, \( \theta  \) the \emph{scale} and   \( \Gamma (x) \) is the \emph{gamma function}:
\begin{equation*}
  \Gamma (x) = \int_{0}^{\infty } t^{x-1} e^{-t} \dd[]{t}
\end{equation*}
The gamma distribution has mean \( k \theta  \) and variance \( k \theta ^2 \).
This shape start to be somehow what we saw in the data.

What is similar to the gamma distribution is the \textbf{Erlang distribution}, where we have the factorial instead of the Gamma function:
\begin{equation}
  P (x) = \frac{\lambda ^k x^{k-1}e^{- \lambda x} }{(k-1)!}
\end{equation}
or the \textbf{Weibull distribution}:
  \begin{equation}
  P(x) =
    \begin{cases}
     \frac{k}{\lambda } \qty(\frac{x}{\lambda })^{k-1} e^{- (x/\lambda )^k} & < \ge 0  \\
    0 & x <0
    \end{cases}
  \end{equation}
All of these distribution are able to reproduce real histograms.

However, the question still remains: how to include non-markovian elements in classical epidemiological models (with the assumption of markovian...)?
We use a trick for the indectious period: \emph{the sum of exponential random variables obeys a Gamma distribution}.
How we are gonna incorporate that in our model? Instead of having just one transition at a coastant rate (expoential distribution), what we need to have to have a gamma distribution?


The trick is the fact that instead of having just one transition, we are gonna include more and more transitions. Instead of having just one single infectious state, individuals move from one  compartment to the other, such that they spend at least some time infectious before starting the recovery. We obtain again a Markovian model.

\subsection{SIR Model with Multiple Infectious Stages}

To repeat, the solution is using \textbf{multiple infectious compartment}, i.e. SIR in well mixed populations becomes \( S I_1 I_2 \dots I_k R \). For instance, we are imposing that these transitions are sequential:
\begin{equation}
\begin{split}
  S + I & \overset{\beta }{\rightarrow } I + I_1   \\
  I_1 & \overset{K \mu  }{\rightarrow } I_2 \\
   I_2 & \overset{K \mu  }{\rightarrow } I_3 \\
   & \vdots \\
   I_k & \overset{K \mu  }{\rightarrow } R
\end{split}
\end{equation}
Hence, if I want to get recovered I need to spent some times infectious, but the model is still markovian! More precisely, the equations are:
\begin{equation}
\begin{split}
  \dv{s}{t} &= - \beta s i  \\
  \dv{i_1}{t} &= \beta s i - K \mu i_1 \\
  \dv{i_2}{t} &= K \mu i_1 - K \mu i_2 \\
  &\vdots \\
  \dv{r}{t} &= K \mu i_k
\end{split}
\end{equation}
where the rate of each \( I \) transition is \( K \mu  \) and with \( i = \sum_{k=1}^{K} i_k   \).
We got that this is the infectious period distribution:
\begin{equation}
  P(\tau ) = \frac{(\mu K)^K}{\Gamma (K)} \tau ^{K-1} e^{- \mu K \tau }
\end{equation}
where the mean is still \( 1/ \mu  \), but the shape is totally different.
which is the gamma function.
We have two special cases:
\begin{itemize}
\item if \( K=1 \), we obtain an exponential distribution;
\item if \( K \rightarrow \infty  \) fixed, we obtain a delta distribution.
\end{itemize}

Other quantities are:
\begin{equation*}
  R_0 = \frac{\beta }{\mu }
\end{equation*}
and the \textbf{final epidemic size}:
\begin{equation*}
  r_ \infty  = 1 - e^{- R_0 r_ \infty }
\end{equation*}
Moreover, we have an early growth:
\begin{equation*}
  i(t) \simeq i_0 e^{\lambda t}
\end{equation*}
instead of \( i(t) \simeq i_0 e^{(\beta - \mu )t}  \). Hence, the disease is growing faster and has a shorter duration.

With \( \lambda  \) as the solution of:
\begin{equation*}
  R_0 = \frac{\lambda }{\mu  \qty(1- \qty(\frac{\lambda }{K \mu } + 1) ^{-K}) }
\end{equation*}

The \( S I_1 I_2 \dots I_k R \) model has several limitaionts:
\begin{itemize}
\item it is defined only for well-mixed populations;
\item focus only on the infectious period distribution. We have that infections are still Markovian and this model only reproduces as Gamma distribution.
\end{itemize}


\subsection{Generalized SIS Model}

Now, we are going to present something which is more general where we can include non-markovian both in recovery and infections.
Is it possible to write down a general model on networks? The answer is  yes, it is a bit more complicated and we still needs some kind of approximation at some point.
In particular, we need a mean-field approximation.

We have to change our point of view. We are gonna use a slightly different approach, i.e. instead of probabilities we are gonna talk about events. The idea is that we are gonna modelling in this case the infections and recoveries with two random numbers which we extract from distribution and are as general as possible.

The ingredients are:
\begin{itemize}
\item a random number \( R_i (t) \): recovery time of node \( i \) when infected;
\item a random number \( M_{ij} (t) \): infection times at which node \( i \) tries to infect node \( j \).
\end{itemize}
In order:
\begin{enumerate}
\item node \( i \) get the infection at time \( t \);
\item we extract the random number \( R_i (t) \) which represents the time in which node \( i \) is gonna recovery (or, the time for which it stay infected);
\item then, we extract the random number  \( M_{ij} (t) \) which reprsenets the number of trials that \( i \) try to infect node \( j \) while infected;
\item we generate a sequence of times
\begin{equation*}
  T_{ij}^{(1)} \le \dots \le T_{ij}^{(M_{ij}(t))} \le R_i (t)
\end{equation*}
in which node \( i \) try to infect node \( j \). For instance, \(  T_{ij}^{(1)} \) is the first time that node \( i \) try to infect node \( j \) then we have the second time and so on;
\item I am gonna repeat the last step for all my neighbours.
\end{enumerate}
Hence, the trasmissibility of the disease is seen as how many trials I am gonna make to infect.
One important thins is that \( R_i (t) \) and \( M_{ij} (t) \) can be drawn from any distribution and not only from the exponential one.
How do we extract the \( T_{ij} \) is not important at this point, because we are only gonna focus on the distribution of \( R_i (t) \) and \( M_{ij} (t) \).


Now, let us make some assumptions to make the model more reasonable and then treat it analytically. We assume that:
\begin{itemize}
\item \( R_i (t) \) and \( M_{ij} (t) \) do not depend on time, i.e. \( R_i (t) \equiv R_i \) and \( M_{ij} (t)  \equiv M_{ij} \);
\item \( R_i (t) \) and \( M_{ij} (t) \)  do not depend on \( i \) and \( j \), i.e. same distribution for all the nodes \( R_i \equiv R \) and \( M_{ij} \equiv M \).
\end{itemize}
hence, we are assuming that these numbers should not depend on time and for instance they are typical for the disease. It is valid both for the recovery and for the infections. However, if we consider restrictions as lockdown and so on these number should change, but for the let us consider the simplest model without such restrictions. Indeed, with these assumptions we are reducing the complexity.

We call:
\begin{itemize}
\item \( \mathbb{E}[R] \), the expected value of \( R \);
\item \( \mathbb{E}[M] \), the expected value of \( M \);
\item \( v_i \), the probability that node \( i \) is infected in the steady state.
\end{itemize}



Now, let us build the model:
\begin{enumerate}
\item let us suppose that we are in the steady state of the system (all the transient are passed).
In a large time interval \( [0,S] \) the number of times node \( j \) has been infected is proportional to \( S \) (it is linear).
Since the length of each infected period is \( E[R] \), the \textbf{number of infected periods} experienced by a node \( j \) (number of times a node has been infected in the interval \( [0,S] \)) can be written as:
\begin{equation*}
  \frac{v_j S}{\mathbb{E}[R]}
\end{equation*}

\item during each infected period, node \( j \) will try to infect \( i \) an average \( E[M] \) number of times. So, the \textbf{total number of infection attempts} from node \( j \) to \( i \) in a large period of time are:
\begin{equation*}
  \frac{v_j S \mathbb{E}[M]}{\mathbb{E}[R]}
\end{equation*}
the number of times \( j \) has been infectious multiplied by the number of infection attempts per each time;

\item then, we make the \textbf{mean-field assumption}: the  conjunct probability that $j$ is infected and $i$ is susceptible is:
\begin{equation*}
  \text{Prob} [ \sigma _i (t)=0, \sigma _j (t)=1] \rightarrow \underbrace{\text{Prob} [\sigma _i (t) = 0]}_{(1-v_i)} \underbrace{\text{Prob} [\sigma _j (t) = 1]}_{v_j}
\end{equation*}

\item we can write the \textbf{total number of successful infection attempts} for \( j \) to \( i \) as:
\begin{equation*}
  S \frac{\mathbb{E}[M]}{\mathbb{E}[R] } v_j (1-v_i)
\end{equation*}
that is the total number of attempts multiplied by the probability that $i$ was not infected.

Summing over all the neighbors of $i$ we have the the \textbf{total number of successful infections} \( i \) will receive during interval \( [0,S] \) is:
\begin{equation*}
  S \sum_{j=1}^{N}  a_{ij} \frac{\mathbb{E}[M]}{\mathbb{E}[R]} v_{j} (1-v_i)
\end{equation*}

\item in the \emph{steady state} the number of successful infections (\(  S \sum_{j=1}^{N}  a_{ij} \frac{\mathbb{E}[M]}{\mathbb{E}[R]} v_{j} (1-v_i) \)) is asymptotically equal to the number of infected periods experienced by \( i \): \( v_i S / E[R] \). Thus we have:
\begin{equation}
  \cancel{S} \sum_{j=1}^{N}  a_{ij} \frac{\mathbb{E}[M]}{\cancel{\mathbb{E}[R]}} v_{j} (1-v_i) = v_i \frac{\cancel{ S}}{\cancel{\mathbb{E}[R]}} \qquad \rightarrow \qquad  v_i = \mathbb{E}[M] (1- v_i) \sum_{j=1}^{N} a_{ij} v_j
\end{equation}
hence the probability of \( i \) being infected depends by the sum over all its neighbours, times the term \( E[M] \) which is the average infection attempts that it is gonna experience during the evolution.
\end{enumerate}

Do the last expression sound familiar? This is exactly the same expression of the IBMF but with a generic infection term \( E[M] \):
\begin{equation*}
  \mu \varepsilon _i^* = \beta ( 1 - \varepsilon _i^*) \sum_{j=1}^{N} a_{ij} \varepsilon _j^*
\end{equation*}

The implications are:
\begin{itemize}
\item the definition of \( M \) implicitly includes the recovery term: \( T_{ij}^{(1)} \le \dots \le T_{ij}^{(M_{ij}(t))} \le \mathcolorbox{green!20}{R_i (t)} \);
\item exponential case: \( E[M] \) is the expected number of infection events in a Poisson preocess with intensity \( \beta  \) within an exponential recovery time with expectation \( 1/ \mu  \). Thus: \( E[M] = \beta / \mu  \).
\item epidemic treshold (lower bound):
\begin{equation*}
  m_c = \mathbb{E}[M_c] = \frac{1}{\Lambda _{max}}
\end{equation*}
\end{itemize}
Hence, this is the form in which we can generate a generic model from.










\end{document}
